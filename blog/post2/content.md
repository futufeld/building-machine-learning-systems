# Preparing Data for Model Training

## From Domain Data to Trained Models

Most training and inference algorithms expect, as input, vectors or matrices of numbers or symbols that encode _something_ about the problem domain. This enables such algorithms to be applied to any data that can be converted into the appropriate representations. However, this also introduces the need for functionality that can take data in its stored form, which is usually dictated by the problem domain, and convert it into a representation that the system's model training functionality can process. This data preparation is more than just an adapter between data in its domain representation and model representation; it can include data aggregation, data filtering, and feature extraction tasks. Since data preparation dictates what data a model receives, this functionality, and any defects it contains, influences the training and inference processes. As such, it is essential that risks to its correctness of this functionality are avoided. This blog post describes strategies for creating data preparation functionality that is testable and maintainable, preserving the integrity of the data it consumes and providing it to the model in the intended form.

## The Role of Data Preparation

An ML system's data preparation functionality sets the application context in which models are trained and used, by defining one or more specific ways in which the ML system can utilise abstract ML techniques - taking the general ideas within the technique and giving them concrete form to address one or more problems within a specific domain. As such, the role of data preparation functionality is to encode the problem that the system is attempting to solve in such a way that the ML techniques implemented within the system can be used to discover solutions. By defining the problem, this functionality affects the discoverability of solutions and the quality of trained models. Understanding the relationship between problem representation and solution discoverability is immensely difficult and motivates much of the research in the field of artificial intelligence. This difficulty is why a strong, explicit, testable problem representation is necessary: understanding exactly how data is prepared for consumption by the training and inference functionality of the system is a precondition for reasoning about how the model performs on the problem.

Data preparation functionality performs its role in three main steps: representation, extraction and encoding:

* **Representation:** This step outlines the logical structure of the domain data stored by the system and defines how it is stored in memory. In its simplest form, this is a collection of user-defined types that structure the data, making it easier to manipulate and serving as implicit documentation. The primary purpose of data representation is to simplify the task of accessing values of interest within the represented data.


* **Extraction:** Two important steps in model design are 1) the selection of the values within domain data that are most meaningful for the problem the model is attempting to solve and 2) the reduction or elimination of redundant values and noise which complicates identifying those meaningful values. Feature _extraction_ is the process of applying algorithms to domain data that implement these aspects of the model design.
* **Encoding:** This is the mechanical task of taking data that is in its more useful form after feature extraction has been performed and converting it into a form that the model can process. This may consist of simple type manipulations necessary due to how the model training and inference algorithms are implemented, or it may involve complicated logical transformations from feature values to specific encodings intended to influence model training in a particular way.

It is common for ML systems to omit or conflate the above steps; for example, the explicit representation of domain data may be omitted in favour of large arrays or matrices that contain all elements of the dataset, or extraction functionality may be implemented in such a way as to specifically produce output in a form that the system's training and inference functionality expects. While this is expedient, it leads to the creation of functionality that is difficult to test and maintain while the system is in operation, and reuse and extend as the scope of the system grows. For these reasons, it is recommended to maintain an explicit separation of the representation, extraction and encoding steps in data preparation. The following section examines how such functionality should be organised to trace data as it passes through the system.

## Organising Data Preparation Functionality

The previous post in this series introduced the notion of generating identifiers for each element of domain data stored by the system. The ability to identify elements of the domain dataset is critical for data and model traceability, as the next post in this series will explore. The primary technical challenge of implementing an ML system's data preparation functionality is to ensure that the ability to trace data back to the domain data from which it originated is possible even as the functionality manipulates that data into arbitrary forms. To address this challenge, the system's data preparation functionality should be organised such that it can transform domain data into the intended form in what is, conceptually, a single action. This enables domain data which is initially paired with its _identifier_ and _attributes_ (assuming supervised learning) to be separated from that information, converted into its encoded form, and then re-paired with that metadata, enabling the encoded data to be traced back to the domain data from which it originated. This section discusses precisely how this can be achieved and the advantages it has for data traceability.

The main complexity of data preparation, which prevents simply transforming domain data and re-pairing it with its metadata, is the existence of feature extraction techniques that must be calibrated on the dataset before use. Consider, for example, stopword filtering in which stopwords are identified based on the distribution of words amongst documents across the dataset, and the filtering of outlier values using thresholds that depend on statistics derived from the dataset. Such features prevent the processing of individual elements of the dataset in isolation, in addition to making the behaviour of the functionality that implements feature extraction difficult to anticipate since it can be affected by any element of the dataset. Should such functionality produce incorrect results, identifying whether this was an issue of the feature calibration or feature extraction aspect of software may not be possible or practical due to the combined responsibility of the functionality and the scale of the data involved in the calculation. Furthermore, the ability to perform feature extraction on a per-element basis is lost when using such techniques.

However, separating the tasks of feature calibration and feature extraction enables the data preparation functionality of ML systems to be organised in such a way that the passage of data through the system can be easily traced and the complexity introduced by calibration controlled, as follows:

1. Domain data is received from the dataset. Each element of domain data obtained in this way is paired with its _identifier_ and _attributes_ metadata.
2. The received domain data is provided to functionality that calibrates the feature extraction process by inspecting the complete dataset.
3. Static configuration values and the values collected in the previous step of this process are used to configure the system's feature extraction functionality.
4. Domain data is separated from its metadata and passes through the desired feature extraction and encoding functionality.
5. The value output in the previous step is re-paired with the corresponding metadata prior to model training.

Aside from the traceability this approach introduces to data passing through the system, the separation of calibration and extraction enables the corresponding functionality to be tested independently and for details at each step of the data preparation process to be captured for diagnostic purposes. This is essential for localising system defects when evidence of flawed model training arises. This should complement efforts to minimise the occurrence of defects through the creation of rich data representations and testable functionality, which are the respective focuses of the following two sections.

## Representing Domain Data

Each element of domain data should be represented using a user-defined type or class. This provides many advantages independent of the problem the system is intended to solve, including:

* **Control:** By explicitly defining how data is represented, control can be exerted over: the values that the data can contain; how the data can be manipulated; and how the aspects of data relate to each other. This is useful for simplifying access to values of interest within the data as well as avoiding risks that the data will be misused.

* **Documentation:** The structure of data can be immensely communicative, not only by describing the data itself but also in the implicit and explicit transformations implied by the structure and related functionality. This information can indicate not only what are valid operations to perform on the data but also what transformations are meaningful to perform.

Consider, for example, how an email can be represented using a user-defined class and the advantages that this provides over a simple string representation. The class can provide direct access to the email's logical parts, such as the sender, receiver, subject and body of the email, whereas the string representation must be parsed to access such information. The class can also provide access to derived data, such as the number of receivers and whether specific attributes are present. Another advantage of the class is that it cannot be manipulated using common string operations. In general, the operations that can be performed on primitive types are rarely sensible to perform on structured data encoded in primitive values (such as emails encoded in strings). Structured data with a rich representation can only be manipulated using functionality present in the ML system, and that functionality can be made to prevent invalid transformations of the data.

From this small example it should be apparent that simply adding structure to data provides a strong foundation from which to build the system's data preparation functionality. The strength of this foundation depends on what domain and derived data is prioritised and in what form it is provided to functionality that requests this data. Although the appropriate representation of data varies on a problem-to-problem basis, there exist general guidelines to assist designing rich representations:

* **Only make data that is relevant to the problem accessible:** Primary data may contain many details that are either irrelevant to the problem the ML system intends to solve or are intended to be hidden from the ML system (for reasons such as, for example, measuring the ability of the ML system to predict that aspect of the primary data). Avoid making this data accessible in its in-memory representation to keep the problem representation as clear as possible and to prevent the risk of such data being erroneously incorporated into model training.
* **Anticipate the most convenient ways to access data:** Once a problem and the problem domain are well understood it is usually possible to anticipate what aspect of domain data will be accessed most frequently and how access to that aspect can be made efficient and user-friendly. Convenient data access can produce more readable and maintainable software by shifting the complexities of data access from the system's feature extraction functionality into its data representation functionality.
* **Represent data according to how it is used in the domain:** Domain data generally consists of values that serve logically independent purposes despite sharing the same functional representation. For example, dates are often stored using strings but the operations typically applied to text rarely make sense to apply to dates. Create custom types that enable values to be manipulated according to their logical structure and purpose within the domain.
* **Only provide access to simple derived data:** The derived data that custom types store and provide access to should be simple in nature and provided primarily for convenience. It should be unambiguous as to how any such data is derived. Derived data that involves the use of parameters or may be affected by implementation decisions should be contained in feature extraction functionality. Avoid moving derived data functionality into the data representation if the intention is to avoid duplicating it across feature extraction components; instead place it in shared modules that those components can access.
* **Return only immutable values to callers:** Make sure that functionality that requests access to any values within the domain data object is not provided direct access to those values, lest they are modified. Ensure that domain data objects only return copies of requested values or immutable references.

Creating rich data representations using these principles can greatly simplify the implementation and testing of the system's remaining data preparation functionality.

Although rich representations of domain data are essential, the utility of creating such representations for data created during feature extraction tasks may vary. Some of the data produced during feature extraction may be short-lived; for example, the data produced by one step in the process may be immediately transformed by the next step. Other data may have a complex or ambiguous encoding that is difficult to improve using a rich data representation; for example, information encoded in large matrices used to calculate specific features. However, some derived data may be sufficiently long-lived or transparently encoded that a rich in-memory representation is useful. Such data should be represented using custom types designed according to the guidelines presented in this section.

## Implementing Feature Extraction Functionality

Control over the complexity of any software can be achieved by decomposing it into small units of functionality implemented in such a way to ensure that they behave in a consistent manner. While this is important for reducing the impact of software defects, and is thus relevant to all software systems, it is particularly important in ML systems to guard against the risk of unintended data dependencies (in which the calculation of some data depends in some way on other data) which may negatively influence model training. Data dependencies become problematic when the functionality that introduces them is not explicitly captured in discrete processes (i.e. functions) that only have access to specific data but is instead distributed across the codebase in operations that have access to a broad scope of data. The intermingling of process logic and uncontrolled access to data enables unintentional data dependencies to occur since any operation may involve any data. Given that such dependencies may not be easily identified and can manifest in unexpected ways, particularly in ML systems where model training is complex and model behaviour is difficult to verify, guarding against their occurrence is essential. This section outlines practices for creating testable functionality and how such functionality can be used to identify defects in ML systems.

The implementation of feature extraction functionality will vary on a project-to-project basis, but all such functionality should be guided by the same principles to pre-emptively guard against defects:

* **Appropriate decomposition:** Feature extraction functionality should be composed of multiple functions that collectively perform the feature extraction task.
* **Single responsibility:** Each function should perform exactly one logical task.
* **Narrow scope:** Each function should only have access to the data necessary to perform its task.

Functions that perform single actions on a narrow subset of data contain fewer interacting operations and therefore fewer opportunities for defects. The separation of responsibilities and partitioning of data access also substantially reduces the risk of unintentional data dependencies. However, these principles do not guarantee the absence of defects and tests are still necessary to ensure that the functionality behaves as expected. A function can only be effectively tested if it has the following properties:

* It is **deterministic:** When applied to the same input the function always produces the same output. This is essential for verifying the behaviour of the function in isolation as well as understanding its behaviour within the system.
* It has **no side-effects:** Applying the function does not result in the modification of any existing values nor does it have an observable effect on the broader system. The intention to perform side-effects should instead be explicitly represented in the function's output, to be performed by other components of the system.
* It is **total:** The function returns a valid value for every possible input. If the function cannot compute a result for every input, then its result type must be able to unambiguously represent this case (enabling the caller to branch in the failure case).

Avoid sources of non-determinism, such as uncontrolled pseudo-random number generators, side-effects, such as file and network I/O, and ambiguous result values, such as `null`. To test a function that exhibits the above properties all that is required are pairs of inputs and the expected outputs - complicated testing setups become superfluous.

A desirable consequence of the principles and properties introduced in this section is the creation of functions that both assume nothing about the context in which they are used and which behave consistently in whatever that context is. Such functions can be easily and thoroughly tested to verify that they perform as expected. Then, integration tests can be created to ensure that the functions interact in the expected ways. Feature extraction tasks typically involve complicated operations such as data aggregation, statistics calculation, data filtering, data normalisation and even the use of intermediate models. Due to this complexity, defects present in this functionality often do not manifest in encoded domain data in a way that can be traced back to the flawed operation. By isolating each operation to a testable function, this complexity is managed and opportunities to localise and eliminate defects are created.

## Data Preparation Forms Part of the Model

As stated in the introduction of this blog post, data preparation functionality defines a specific context in which abstract ML techniques can be applied. Decisions made in creating that context, such as how features are extracted from the data and how those features are prepared for processing by model functionality, affect model performance. If a trained model is removed from this context, the risk exists that it will be presented data in which different features have been extracted or the same features are encoded differently, in which case the model is likely to produce non-sensical results. Due to their generality, ML techniques, and thus also their implementations, provide little inherent defense against the misuse of trained models. For this reason, the functionality that enables inference using trained models usually should consist of both the functionality that prepares data for processing by the model in addition to the functionality that performs model inference. The functionality that provides the context for model training often must be present to provide that same context for model inference.

The combination of data preparation functionality with model inference functionality has a number of practical implications. First, the system's data preparation functionality must be organised in such a way that aspects of it can be used in both the training and inference modes of the system. This generally involves separating statistical and calibration functionality, which can only be applied to datasets, from feature extraction functionality, which applies to individual elements of data (as discussed in _Organising Data Preparation Functionality_). Second, the model in its serialised form must contain all of the data necessary to configure the data preparation functionality to match its configuration during training. Deserialising a model should produce an artefact that can immediately perform inference on elements of domain data. As the next blog post in this series will demonstrate, the ability to configure data preparation functionality also assists model traceability and training repeatability.

## Control Data Preparation

Implementing training and inference algorithms is a relatively straightforward task; the algorithms define the requirements of the functionality, and the implementations need only satisfy the algorithms. The generality of ML techniques insulates their implementations from the complexities of the application domain. Data preparation functionality, in contrast, is defined by specificity, and thus is affected by the complexities of both the application domain and the system in which it operates. It is through these complexities that many defects may enter the system. Unfortunately, the nature of machine learning systems is such that defects may only become apparent through the behaviour of trained models and, even then, only be observable in limited ways due to models' black box nature. The careful organisation and testing of data preparation functionality is essential to mitigate such defects.

